# cogs/gemini_cog.py

import discord
from discord import app_commands  # app_commands ì„í¬íŠ¸
from discord.ext import commands
import google.generativeai as genai
import os
import logging
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(name)s: %(message)s')
logger = logging.getLogger(__name__)


class GeminiCog(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logger.error("ğŸš¨ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cogë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.model = None
            return

        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')  # ë˜ëŠ” 'gemini-pro' ë“±
            logger.info("âœ… Gemini Cogê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìœ¼ë©°, Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.model = None

    @commands.Cog.listener()
    async def on_ready(self):
        if not self.api_key:
            logger.warning("âš ï¸ GeminiCog: GEMINI_API_KEYê°€ ì—†ì–´ Gemini ê´€ë ¨ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif not self.model:
            logger.warning("âš ï¸ GeminiCog: Gemini ëª¨ë¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í•˜ì—¬ ê´€ë ¨ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            logger.info(f'{self.bot.user.name} ë´‡ì˜ GeminiCogê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.')

    @app_commands.command(name="ai-chat", description="âœ¨ Gemini AIì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤.")
    @app_commands.describe(prompt="Gemini AIì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤.")
    async def ask_gemini_slash(self, interaction: discord.Interaction, prompt: str):
        """Gemini AI ëª¨ë¸ì—ê²Œ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìš”ì²­í•©ë‹ˆë‹¤."""

        if not self.model:
            await interaction.response.send_message(
                "ì£„ì†¡í•©ë‹ˆë‹¤, Gemini AI ëª¨ë¸ì´ í˜„ì¬ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜¥ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.",
                ephemeral=True
            )
            return

        if not prompt:
            await interaction.response.send_message(
                "ğŸ¤” ì§ˆë¬¸ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!",
                ephemeral=True
            )
            return

        # API í˜¸ì¶œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ deferë¥¼ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µ ëŒ€ê¸° ì¤‘ì„ì„ ì•Œë¦¼
        # ephemeral=Falseë¡œ ì„¤ì •í•˜ë©´ "Bot is thinking..." ë©”ì‹œì§€ê°€ ê³µê°œì ìœ¼ë¡œ ë³´ì„
        # ë‹µë³€ ìì²´ë¥¼ ephemeral=Trueë¡œ í•˜ê³  ì‹¶ë‹¤ë©´ ì—¬ê¸°ì„œ ephemeral=Trueë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŒ
        await interaction.response.defer(thinking=True, ephemeral=False)

        try:
            logger.info(f"â¡ï¸ Gemini API ìš”ì²­ (Slash): '{prompt}' (ìš”ì²­ì: {interaction.user.name})")

            # ë¹„ë™ê¸° API í˜¸ì¶œ
            response = await self.model.generate_content_async(prompt)

            response_text = ""
            if response.text:
                response_text = response.text
                logger.info(f"â¬…ï¸ Gemini API ì‘ë‹µ ì„±ê³µ (ìš”ì²­ì: {interaction.user.name})")
            else:
                # ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜, ì•ˆì „ìƒì˜ ì´ìœ ë¡œ ì°¨ë‹¨ëœ ê²½ìš° ì²˜ë¦¬
                block_reason = response.prompt_feedback.block_reason if response.prompt_feedback else "ì•Œ ìˆ˜ ì—†ìŒ"
                error_message_parts = [f"Gemini AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ğŸ˜” (ì°¨ë‹¨ ì‚¬ìœ : {block_reason})"]

                candidate_info_available = hasattr(response, 'candidates') and response.candidates
                if candidate_info_available:
                    finish_reason = response.candidates[0].finish_reason.name if response.candidates[
                        0].finish_reason else "ì•Œ ìˆ˜ ì—†ìŒ"
                    if finish_reason != "STOP":  # STOPì´ ì•„ë‹Œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì¢…ë£Œëœ ê²½ìš°
                        error_message_parts.append(f"ì¢…ë£Œ ì‚¬ìœ : {finish_reason}")

                    if response.candidates[0].safety_ratings:
                        safety_info_parts = [
                            f"{s.category.name.replace('HARM_CATEGORY_', '')}: {s.probability.name}"
                            for s in response.candidates[0].safety_ratings
                            if s.probability.name not in ["NEGLIGIBLE", "LOW"]  # ë³´í†µ ë˜ëŠ” ë†’ìŒë§Œ í‘œì‹œ (ì¡°ì • ê°€ëŠ¥)
                        ]
                        if safety_info_parts:
                            error_message_parts.append("ê°ì§€ëœ ì•ˆì „ ë¬¸ì œ: " + ", ".join(safety_info_parts))

                response_text = "\n".join(error_message_parts)
                logger.warning(
                    f"Gemini API ì‘ë‹µ ì—†ìŒ ë˜ëŠ” ì°¨ë‹¨ë¨ (ìš”ì²­ì: {interaction.user.name}, ì‚¬ìœ : {block_reason}, "
                    f"ì¢…ë£Œ ì‚¬ìœ : {finish_reason if candidate_info_available and 'finish_reason' in locals() else 'N/A'})"
                )

            # deferë¥¼ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ followup.sendë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.
            if len(response_text) > 1990:
                chunks = [response_text[i:i + 1990] for i in range(0, len(response_text), 1990)]
                await interaction.followup.send(chunks[0])  # ì²« ë²ˆì§¸ ì²­í¬ ì „ì†¡
                for chunk in chunks[1:]:
                    # í›„ì† ì²­í¬ëŠ” ì±„ë„ì— ì§ì ‘ ë³´ë‚´ê±°ë‚˜, followupì„ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš©
                    # followupì„ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš©í•˜ë©´ ê° ì²­í¬ê°€ ë³„ë„
                    await interaction.followup.send(chunk)
            else:
                await interaction.followup.send(response_text)

        except Exception as e:
            logger.error(f"Gemini API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Slash): {e} (ìš”ì²­ì: {interaction.user.name})")
            # ì´ë¯¸ defer ë˜ì—ˆìœ¼ë¯€ë¡œ followup.send ì‚¬ìš©
            await interaction.followup.send(
                f"ì£„ì†¡í•©ë‹ˆë‹¤, Gemini APIì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: `{type(e).__name__}: {e}` ğŸ˜­",
                ephemeral=True  # ì˜¤ë¥˜ëŠ” ì‚¬ìš©ìì—ê²Œë§Œ ë³´ì´ë„ë¡
            )


async def setup(bot: commands.Bot):
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    cog_instance = GeminiCog(bot)

    if not gemini_api_key:
        logger.error("ğŸš¨ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ GeminiCogë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê¸°ëŠ¥ ì œí•œë¨).")
        # CogëŠ” ì¶”ê°€í•˜ë˜, modelì´ Noneì´ë¯€ë¡œ ì»¤ë§¨ë“œ ì‚¬ìš© ì‹œ ì˜¤ë¥˜
    # API í‚¤ê°€ ìˆë”ë¼ë„ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ self.modelì´ None

    await bot.add_cog(cog_instance)
    if cog_instance.model:  # ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ê²½ìš°ì—ë§Œ
        logger.info("ğŸš€ GeminiCogê°€ ë´‡ì— ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìœ¼ë©°, ìŠ¬ë˜ì‹œ ì»¤ë§¨ë“œ ë“±ë¡ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        logger.warning("âš ï¸ GeminiCogê°€ ë´‡ì— ì¶”ê°€ë˜ì—ˆìœ¼ë‚˜, Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")